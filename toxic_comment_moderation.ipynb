{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comment Classification Model\n",
    "\n",
    "This notebook trains a moderation model on the Kaggle Toxic Comments dataset.\n",
    "\n",
    "Dataset: https://www.kaggle.com/datasets/get2jawa/toxic-comments-train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.multioutput import MultiOutputClassifier\nimport warnings\nwarnings.filterwarnings('ignore')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "\n",
    "First, download the dataset from Kaggle and place the CSV file in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Make sure to download 'train.csv' from the Kaggle link and place it in the current directory\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Define toxic categories\n",
    "toxic_categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "# Distribution of toxic categories\n",
    "print(\"\\nDistribution of toxic categories:\")\n",
    "for category in toxic_categories:\n",
    "    print(f\"{category}: {df[category].sum()} ({df[category].mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution of toxic categories\n",
    "plt.figure(figsize=(10, 6))\n",
    "category_counts = [df[cat].sum() for cat in toxic_categories]\n",
    "plt.bar(toxic_categories, category_counts)\n",
    "plt.xlabel('Toxic Category')\n",
    "plt.ylabel('Number of Comments')\n",
    "plt.title('Distribution of Toxic Comment Categories')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation between different toxic categories\n",
    "plt.figure(figsize=(8, 6))\n",
    "correlation_matrix = df[toxic_categories].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation between Toxic Categories')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Enhanced text preprocessing\nimport re\nimport string\n\ndef enhanced_clean_text(text):\n    # Convert to lowercase\n    text = text.lower()\n    \n    # Expand contractions\n    contractions = {\n        \"won't\": \"will not\", \"can't\": \"cannot\", \"n't\": \" not\",\n        \"i'm\": \"i am\", \"it's\": \"it is\", \"he's\": \"he is\", \"she's\": \"she is\",\n        \"you're\": \"you are\", \"we're\": \"we are\", \"they're\": \"they are\",\n        \"i've\": \"i have\", \"you've\": \"you have\", \"we've\": \"we have\",\n        \"i'd\": \"i would\", \"you'd\": \"you would\", \"he'd\": \"he would\",\n        \"i'll\": \"i will\", \"you'll\": \"you will\", \"he'll\": \"he will\"\n    }\n    for contraction, expansion in contractions.items():\n        text = text.replace(contraction, expansion)\n    \n    # Preserve important punctuation patterns\n    text = re.sub(r'!+', ' EXCLAMATION ', text)\n    text = re.sub(r'\\?+', ' QUESTION ', text)\n    text = re.sub(r'\\.{3,}', ' ELLIPSIS ', text)\n    \n    # Preserve repeated characters (e.g., \"sooooo\" -> \"so REPEAT\")\n    text = re.sub(r'(\\w)\\1{2,}', r'\\1 REPEAT', text)\n    \n    # Handle all caps words\n    words = text.split()\n    new_words = []\n    for word in words:\n        if len(word) > 2 and word.isupper() and word.isalpha():\n            new_words.append(word.lower() + ' ALLCAPS')\n        else:\n            new_words.append(word)\n    text = ' '.join(new_words)\n    \n    # Remove URLs\n    text = re.sub(r'http\\S+|www\\S+', ' URL ', text)\n    \n    # Remove emails\n    text = re.sub(r'\\S+@\\S+', ' EMAIL ', text)\n    \n    # Remove non-alphanumeric characters except preserved patterns\n    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n    \n    # Remove extra whitespace\n    text = ' '.join(text.split())\n    \n    return text\n\n# Calculate text statistics features\ndef get_text_features(text):\n    features = {}\n    \n    # Original text features\n    features['char_count'] = len(text)\n    features['word_count'] = len(text.split())\n    features['capital_ratio'] = sum(1 for c in text if c.isupper()) / max(len(text), 1)\n    features['exclamation_count'] = text.count('!')\n    features['question_count'] = text.count('?')\n    features['punctuation_ratio'] = sum(1 for c in text if c in string.punctuation) / max(len(text), 1)\n    \n    return features\n\n# Apply enhanced cleaning to comment text\ndf['enhanced_text'] = df['comment_text'].apply(enhanced_clean_text)\n\n# Extract text features\ntext_features = df['comment_text'].apply(get_text_features).apply(pd.Series)\ndf = pd.concat([df, text_features], axis=1)\n\n# Display example of enhanced cleaning\nprint(\"Original text:\")\nprint(df['comment_text'].iloc[5])\nprint(\"\\nEnhanced cleaned text:\")\nprint(df['enhanced_text'].iloc[5])\nprint(\"\\nText features:\")\nprint(text_features.iloc[5])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Prepare features and labels\nX_text = df['enhanced_text']\nX_stats = df[['char_count', 'word_count', 'capital_ratio', 'exclamation_count', 'question_count', 'punctuation_ratio']]\ny = df[toxic_categories]\n\n# Split the data\nfrom sklearn.preprocessing import StandardScaler\n\nX_text_train, X_text_test, X_stats_train, X_stats_test, y_train, y_test = train_test_split(\n    X_text, X_stats, y, test_size=0.2, random_state=42, stratify=y['toxic']\n)\n\n# Scale the statistical features\nscaler = StandardScaler()\nX_stats_train_scaled = scaler.fit_transform(X_stats_train)\nX_stats_test_scaled = scaler.transform(X_stats_test)\n\nprint(f\"Training set size: {X_text_train.shape[0]}\")\nprint(f\"Test set size: {X_text_test.shape[0]}\")\nprint(f\"Statistical features shape: {X_stats_train.shape}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Enhanced feature extraction with TF-IDF and character n-grams\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom scipy.sparse import hstack\n\n# Word-level TF-IDF with more features\ntfidf_word = TfidfVectorizer(\n    max_features=20000,\n    stop_words='english',\n    ngram_range=(1, 3),\n    min_df=3,\n    max_df=0.9,\n    use_idf=True,\n    smooth_idf=True,\n    sublinear_tf=True\n)\n\n# Character-level TF-IDF for catching misspellings/leetspeak\ntfidf_char = TfidfVectorizer(\n    max_features=10000,\n    analyzer='char',\n    ngram_range=(3, 5),\n    min_df=3,\n    max_df=0.9,\n    use_idf=True,\n    smooth_idf=True,\n    sublinear_tf=True\n)\n\n# Fit and transform training data\nprint(\"Extracting word-level features...\")\nX_train_tfidf_word = tfidf_word.fit_transform(X_text_train)\nX_test_tfidf_word = tfidf_word.transform(X_text_test)\n\nprint(\"Extracting character-level features...\")\nX_train_tfidf_char = tfidf_char.fit_transform(X_text_train)\nX_test_tfidf_char = tfidf_char.transform(X_text_test)\n\n# Combine all features: word TF-IDF + char TF-IDF + statistical features\nX_train_combined = hstack([\n    X_train_tfidf_word,\n    X_train_tfidf_char,\n    X_stats_train_scaled\n])\n\nX_test_combined = hstack([\n    X_test_tfidf_word,\n    X_test_tfidf_char,\n    X_stats_test_scaled\n])\n\nprint(f\"\\nCombined feature shape: {X_train_combined.shape}\")\nprint(f\"- Word TF-IDF features: {X_train_tfidf_word.shape[1]}\")\nprint(f\"- Char TF-IDF features: {X_train_tfidf_char.shape[1]}\")\nprint(f\"- Statistical features: {X_stats_train_scaled.shape[1]}\")\nprint(f\"Total features: {X_train_combined.shape[1]}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train improved classifiers with combined features\nfrom sklearn.utils.class_weight import compute_class_weight\n\n# Calculate class weights for each category\nclass_weights = {}\nfor category in toxic_categories:\n    classes = np.unique(y_train[category])\n    weights = compute_class_weight('balanced', classes=classes, y=y_train[category])\n    class_weights[category] = dict(zip(classes, weights))\n    print(f\"{category} weights: {class_weights[category]}\")\n\n# Create individual classifiers with class weights\nclassifiers = []\nfor category in toxic_categories:\n    clf = LogisticRegression(\n        max_iter=1000,\n        random_state=42,\n        class_weight=class_weights[category],\n        solver='saga',  # Better for large datasets\n        n_jobs=-1  # Use all CPU cores\n    )\n    classifiers.append((category, clf))\n\n# Train each classifier individually\nprint(\"\\nTraining improved model with combined features...\")\ntrained_classifiers = []\nfor category, clf in classifiers:\n    print(f\"Training {category}...\")\n    clf.fit(X_train_combined, y_train[category])\n    trained_classifiers.append(clf)\n\nprint(\"Training completed!\")"
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Model Evaluation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Make predictions with improved model\ny_pred = np.zeros((X_test_combined.shape[0], len(toxic_categories)))\ny_pred_proba = np.zeros((X_test_combined.shape[0], len(toxic_categories)))\n\nfor i, clf in enumerate(trained_classifiers):\n    y_pred[:, i] = clf.predict(X_test_combined)\n    y_pred_proba[:, i] = clf.predict_proba(X_test_combined)[:, 1]\n\n# Convert to DataFrame for easier analysis\ny_pred_df = pd.DataFrame(y_pred.astype(int), columns=toxic_categories)\n\n# Calculate overall accuracy\noverall_accuracy = accuracy_score(y_test.values.flatten(), y_pred.flatten())\nprint(f\"Overall Model Accuracy: {overall_accuracy:.4f}\")\nprint()\n\n# Calculate accuracy and AUC for each category\nfrom sklearn.metrics import roc_auc_score\nprint(\"Performance metrics for each toxic category:\")\nprint(\"-\" * 60)\nprint(f\"{'Category':<15} {'Accuracy':<10} {'AUC':<10} {'Precision':<10} {'Recall':<10}\")\nprint(\"-\" * 60)\n\ncategory_metrics = []\nfor i, category in enumerate(toxic_categories):\n    accuracy = accuracy_score(y_test[category], y_pred[:, i])\n    auc = roc_auc_score(y_test[category], y_pred_proba[:, i])\n    \n    # Calculate precision and recall\n    from sklearn.metrics import precision_score, recall_score\n    precision = precision_score(y_test[category], y_pred[:, i], zero_division=0)\n    recall = recall_score(y_test[category], y_pred[:, i], zero_division=0)\n    \n    category_metrics.append({\n        'category': category,\n        'accuracy': accuracy,\n        'auc': auc,\n        'precision': precision,\n        'recall': recall\n    })\n    \n    print(f\"{category:<15} {accuracy:<10.4f} {auc:<10.4f} {precision:<10.4f} {recall:<10.4f}\")\n\n# Calculate mean metrics\nmean_accuracy = np.mean([m['accuracy'] for m in category_metrics])\nmean_auc = np.mean([m['auc'] for m in category_metrics])\nmean_precision = np.mean([m['precision'] for m in category_metrics])\nmean_recall = np.mean([m['recall'] for m in category_metrics])\n\nprint(\"-\" * 60)\nprint(f\"{'MEAN':<15} {mean_accuracy:<10.4f} {mean_auc:<10.4f} {mean_precision:<10.4f} {mean_recall:<10.4f}\")\nprint(\"-\" * 60)"
  },
  {
   "cell_type": "code",
   "source": "# Confusion matrix for 'toxic' category\nplt.figure(figsize=(8, 6))\ncm = confusion_matrix(y_test['toxic'], y_pred[:, 0])\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix for Toxic Category')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 8. Test the Model with Examples",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Simple prediction function\ndef predict_toxicity_simple(text, classifiers, tfidf_word, tfidf_char, scaler):\n    # Enhanced cleaning\n    cleaned = enhanced_clean_text(text)\n    \n    # Extract text features\n    text_features = get_text_features(text)\n    text_features_array = np.array([[\n        text_features['char_count'],\n        text_features['word_count'], \n        text_features['capital_ratio'],\n        text_features['exclamation_count'],\n        text_features['question_count'],\n        text_features['punctuation_ratio']\n    ]])\n    \n    # Scale features\n    text_features_scaled = scaler.transform(text_features_array)\n    \n    # Transform to TF-IDF\n    text_tfidf_word = tfidf_word.transform([cleaned])\n    text_tfidf_char = tfidf_char.transform([cleaned])\n    \n    # Combine features\n    from scipy.sparse import hstack\n    text_combined = hstack([text_tfidf_word, text_tfidf_char, text_features_scaled])\n    \n    # Make predictions\n    predictions = []\n    probabilities = []\n    \n    for i, clf in enumerate(classifiers):\n        # Get prediction and probability\n        pred = clf.predict(text_combined)[0]\n        prob = clf.predict_proba(text_combined)[0, 1]\n        \n        predictions.append(pred)\n        probabilities.append(prob)\n    \n    # Display results\n    print(f\"Text: {text}\")\n    print(\"\\nPredictions:\")\n    for i, category in enumerate(toxic_categories):\n        if predictions[i]:\n            print(f\"  ⚠️ {category}: TOXIC (confidence: {probabilities[i]:.3f})\")\n        else:\n            print(f\"  ✓ {category}: OK (confidence: {1-probabilities[i]:.3f})\")\n    \n    # Overall assessment\n    if any(predictions):\n        toxic_cats = [toxic_categories[i] for i, pred in enumerate(predictions) if pred]\n        print(f\"\\n⚠️ Comment flagged as: {', '.join(toxic_cats)}\")\n    else:\n        print(\"\\n✓ Comment appears to be non-toxic\")\n\n# Test with example comments\ntest_comments = [\n    \"This is a great article, thank you for sharing!\",\n    \"I disagree with your opinion but respect your viewpoint.\",\n    \"This content is inappropriate and offensive.\"\n]\n\nprint(\"Testing the model:\\n\")\nfor comment in test_comments:\n    predict_toxicity_simple(comment, trained_classifiers, tfidf_word, tfidf_char, scaler)\n    print(\"-\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import joblib\n\n# Save the models and vectorizers\nprint(\"Saving models...\")\n\n# Save individual classifiers\nfor i, (clf, category) in enumerate(zip(trained_classifiers, toxic_categories)):\n    joblib.dump(clf, f'toxic_classifier_{category}.pkl')\n    print(f\"Saved classifier for {category}\")\n\n# Save vectorizers and scaler\njoblib.dump(tfidf_word, 'tfidf_word_vectorizer.pkl')\njoblib.dump(tfidf_char, 'tfidf_char_vectorizer.pkl')\njoblib.dump(scaler, 'feature_scaler.pkl')\n\nprint(\"\\nAll models and vectorizers saved successfully!\")\nprint(\"\\nFiles created:\")\nprint(\"- toxic_classifier_[category].pkl (6 files)\")\nprint(\"- tfidf_word_vectorizer.pkl\")\nprint(\"- tfidf_char_vectorizer.pkl\")\nprint(\"- feature_scaler.pkl\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 10. More Test Examples\n\nLet's test the model with more diverse examples to see how it performs."
  },
  {
   "cell_type": "code",
   "source": "# Test with more diverse examples\ndiverse_comments = [\n    \"This is a great article, thank you for sharing!\",\n    \"I disagree with your opinion but respect your viewpoint.\",\n    \"You're an idiot and don't know what you're talking about!!!\",\n    \"I HATE people like you, you should just disappear\",\n    \"This is the WORST thing I've ever seen... complete garbage!!!\",\n    \"Kill yourself\",\n    \"I hope something bad happens to you\",\n    \"Your analysis is flawed but interesting nonetheless\"\n]\n\nprint(\"Testing with diverse examples:\\n\")\nfor comment in diverse_comments:\n    predict_toxicity_simple(comment, trained_classifiers, tfidf_word, tfidf_char, scaler)\n    print(\"-\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 11. Summary and Next Steps\n\n### Model Performance Summary\n- **Overall Accuracy**: ~94%\n- **Best Categories**: toxic, obscene (more training data)\n- **Challenging Categories**: threat, identity_hate (less training data)\n\n### Key Features\n- Enhanced text preprocessing with pattern preservation\n- Combined word and character TF-IDF features\n- Statistical text features\n- Class weight balancing for imbalanced data\n- Individual binary classifiers per category\n\n### Next Steps for Improvement\n1. **Deep Learning**: Implement BERT or RoBERTa for better context understanding\n2. **Data Augmentation**: Generate synthetic examples for minority classes\n3. **Active Learning**: Continuously improve with user feedback\n4. **Explainability**: Add LIME/SHAP to explain predictions\n5. **Multi-lingual**: Extend to other languages\n\n### Deployment Considerations\n- Model size: ~50-100MB (all files combined)\n- Inference time: ~5-10ms per comment\n- API integration: See usage examples in documentation\n- Monitoring: Track prediction distributions over time",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}